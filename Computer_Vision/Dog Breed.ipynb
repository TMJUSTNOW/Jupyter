{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Breeds\n",
    "\n",
    "https://www.kaggle.com/orangutan/keras-vgg19-starter\n",
    "\n",
    "https://www.kaggle.com/gaborfodor/use-pretrained-keras-models-lb-0-3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breed_class.csv',\n",
       " 'labels.csv',\n",
       " 'logs',\n",
       " 'models',\n",
       " 'sample_submission.csv',\n",
       " 'save',\n",
       " 'test',\n",
       " 'train',\n",
       " 'VGG19.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"D:\\My Computer\\DATA\\Dog_Breed_Identification\")\n",
    "\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "sample_submission= pd.read_csv(\"sample_submission.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID has 32 characters\n",
    "# File names have 36 characters\n",
    "# suggesting the four last digits differentiate the dog within breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog Breed Number: (10222, 2)\n",
      "Training Size: 10222\n",
      "Test Size: 10357\n",
      "Sample Sub Size: (10357, 121)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dog Breed Number:\", labels.shape)\n",
    "print(\"Training Size:\", len(os.listdir(train_dir)))\n",
    "print(\"Test Size:\", len(os.listdir(test_dir)))\n",
    "print(\"Sample Sub Size:\", sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10222/10222 [00:20<00:00, 490.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def dataprep():\n",
    "    targets_series = pd.Series(labels['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "\n",
    "    im_size = 90\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "\n",
    "    i = 0 \n",
    "    for f, breed in tqdm(labels.values):\n",
    "        img = cv2.imread('train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "\n",
    "    # To Pickle\n",
    "    for (i,x) in [(x_train, \"x_train\"), (y_train,\"y_train\"), (x_test, 'x_test')]:\n",
    "        with open(\"{}.pickle\".format(x), 'wb') as f:\n",
    "            pickle.dump(i, f)\n",
    "\n",
    "#dataprep()\n",
    "        \n",
    "for name in results[\"Model\"]:\n",
    "    open_file = open(os.path.join(path,\"Pickle/{}.pickle\".format(name)), \"rb\")\n",
    "    dic[name] = pickle.load(open_file)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10357/10357 [00:21<00:00, 489.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(sample_submission['id'].values):\n",
    "    img = cv2.imread('test/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_raw = np.array(y_train, np.uint8)\n",
    "x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 90, 90, 3)\n",
      "(10222, 120)\n",
      "(10357, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_class = y_train_raw.shape[1]\n",
    "X_train, X_valid, Y_train, Y_valid = \\\n",
    "train_test_split(x_train_raw, y_train_raw, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "# Write\n",
    "def write_model(model, modelname):\n",
    "    preds = model.predict(x_test, verbose=0)\n",
    "    sub = pd.DataFrame(preds)\n",
    "    # Set column names to those generated by the one-hot encoding earlier\n",
    "    col_names = one_hot.columns.values\n",
    "    sub.columns = col_names\n",
    "    # Insert the column id from the sample_submission at the start of the data frame\n",
    "    sub.insert(0, 'id', sample_submission['id'])\n",
    "    sub.to_csv(\"{}.csv\".format(modelname), index=False)\n",
    "       \n",
    "    \n",
    "# Store Result, Parameters and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 20,270,264\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19 Pretrained Model\n",
    "# Not sure if I really need to iterate over this?\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "# Research Base Models\n",
    "base_model = VGG19(weights='imagenet',\n",
    "                   include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "# Add a new top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# This is the model we will train\n",
    "# This outputs the softmax, probabilistic consideration\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with Min_delta\n",
    "ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=40,\n",
    "          verbose=1, mode='auto')\n",
    "# Figure out how to assign name to it\n",
    "TB = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=2,  \n",
    "          write_graph=True, write_images=False)\n",
    "# Broken?\n",
    "MC = keras.callbacks.ModelCheckpoint('./save', monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True,\n",
    "                             mode='auto', period=5)\n",
    "\n",
    "\n",
    "callbacks_list = [ES,TB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=foo:\"D:\\My Computer\\DATA\\Dog_Breed_Identification\\logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 1534 samples\n",
      "Epoch 1/200\n",
      "51s - loss: 4.5531 - acc: 0.0535 - val_loss: 4.2798 - val_acc: 0.0919\n",
      "Epoch 2/200\n",
      "14s - loss: 3.5916 - acc: 0.1953 - val_loss: 4.1482 - val_acc: 0.0939\n",
      "Epoch 3/200\n",
      "51s - loss: 3.1000 - acc: 0.2906 - val_loss: 4.0341 - val_acc: 0.1330\n",
      "Epoch 4/200\n",
      "14s - loss: 2.7420 - acc: 0.3714 - val_loss: 4.0110 - val_acc: 0.1297\n",
      "Epoch 5/200\n",
      "51s - loss: 2.4695 - acc: 0.4380 - val_loss: 4.0067 - val_acc: 0.1395\n",
      "Epoch 6/200\n",
      "14s - loss: 2.2335 - acc: 0.5033 - val_loss: 4.0338 - val_acc: 0.1278\n",
      "Epoch 7/200\n",
      "50s - loss: 2.0288 - acc: 0.5550 - val_loss: 4.0516 - val_acc: 0.1382\n",
      "Epoch 8/200\n",
      "14s - loss: 1.8598 - acc: 0.6047 - val_loss: 4.0890 - val_acc: 0.1362\n",
      "Epoch 9/200\n",
      "51s - loss: 1.7059 - acc: 0.6462 - val_loss: 4.1251 - val_acc: 0.1336\n",
      "Epoch 10/200\n",
      "14s - loss: 1.5735 - acc: 0.6838 - val_loss: 4.1369 - val_acc: 0.1362\n",
      "Epoch 11/200\n",
      "51s - loss: 1.4448 - acc: 0.7230 - val_loss: 4.1621 - val_acc: 0.1369\n",
      "Epoch 12/200\n",
      "14s - loss: 1.3351 - acc: 0.7484 - val_loss: 4.2088 - val_acc: 0.1304\n",
      "Epoch 13/200\n",
      "51s - loss: 1.2374 - acc: 0.7761 - val_loss: 4.2431 - val_acc: 0.1428\n",
      "Epoch 14/200\n",
      "14s - loss: 1.1439 - acc: 0.8021 - val_loss: 4.2627 - val_acc: 0.1395\n",
      "Epoch 15/200\n",
      "52s - loss: 1.0528 - acc: 0.8293 - val_loss: 4.3115 - val_acc: 0.1421\n",
      "Epoch 16/200\n",
      "14s - loss: 0.9777 - acc: 0.8481 - val_loss: 4.3556 - val_acc: 0.1408\n",
      "Epoch 17/200\n",
      "51s - loss: 0.9033 - acc: 0.8644 - val_loss: 4.3774 - val_acc: 0.1408\n",
      "Epoch 18/200\n",
      "14s - loss: 0.8376 - acc: 0.8825 - val_loss: 4.4387 - val_acc: 0.1375\n",
      "Epoch 19/200\n",
      "51s - loss: 0.7760 - acc: 0.8973 - val_loss: 4.5124 - val_acc: 0.1330\n",
      "Epoch 20/200\n",
      "14s - loss: 0.7186 - acc: 0.9121 - val_loss: 4.5371 - val_acc: 0.1362\n",
      "Epoch 21/200\n",
      "50s - loss: 0.6635 - acc: 0.9232 - val_loss: 4.6088 - val_acc: 0.1291\n",
      "Epoch 22/200\n",
      "14s - loss: 0.6146 - acc: 0.9330 - val_loss: 4.6248 - val_acc: 0.1402\n",
      "Epoch 23/200\n",
      "52s - loss: 0.5693 - acc: 0.9467 - val_loss: 4.6831 - val_acc: 0.1362\n",
      "Epoch 24/200\n",
      "14s - loss: 0.5252 - acc: 0.9527 - val_loss: 4.7442 - val_acc: 0.1278\n",
      "Epoch 25/200\n",
      "52s - loss: 0.4845 - acc: 0.9593 - val_loss: 4.7647 - val_acc: 0.1356\n",
      "Epoch 26/200\n",
      "14s - loss: 0.4492 - acc: 0.9663 - val_loss: 4.8006 - val_acc: 0.1323\n",
      "Epoch 27/200\n",
      "52s - loss: 0.4143 - acc: 0.9716 - val_loss: 4.8477 - val_acc: 0.1291\n",
      "Epoch 28/200\n",
      "14s - loss: 0.3857 - acc: 0.9759 - val_loss: 4.8731 - val_acc: 0.1310\n",
      "Epoch 29/200\n",
      "52s - loss: 0.3535 - acc: 0.9799 - val_loss: 4.9627 - val_acc: 0.1265\n",
      "Epoch 30/200\n",
      "14s - loss: 0.3251 - acc: 0.9830 - val_loss: 5.0074 - val_acc: 0.1278\n",
      "Epoch 31/200\n",
      "51s - loss: 0.3001 - acc: 0.9868 - val_loss: 5.0502 - val_acc: 0.1304\n",
      "Epoch 32/200\n",
      "14s - loss: 0.2761 - acc: 0.9884 - val_loss: 5.1166 - val_acc: 0.1304\n",
      "Epoch 33/200\n",
      "51s - loss: 0.2566 - acc: 0.9910 - val_loss: 5.1372 - val_acc: 0.1258\n",
      "Epoch 34/200\n",
      "14s - loss: 0.2362 - acc: 0.9921 - val_loss: 5.1755 - val_acc: 0.1304\n",
      "Epoch 35/200\n",
      "50s - loss: 0.2201 - acc: 0.9934 - val_loss: 5.2049 - val_acc: 0.1317\n",
      "Epoch 36/200\n",
      "14s - loss: 0.2004 - acc: 0.9959 - val_loss: 5.2568 - val_acc: 0.1323\n",
      "Epoch 37/200\n",
      "51s - loss: 0.1841 - acc: 0.9969 - val_loss: 5.3098 - val_acc: 0.1232\n",
      "Epoch 38/200\n",
      "14s - loss: 0.1724 - acc: 0.9964 - val_loss: 5.3699 - val_acc: 0.1252\n",
      "Epoch 39/200\n",
      "51s - loss: 0.1557 - acc: 0.9969 - val_loss: 5.3719 - val_acc: 0.1258\n",
      "Epoch 40/200\n",
      "14s - loss: 0.1451 - acc: 0.9982 - val_loss: 5.4682 - val_acc: 0.1245\n",
      "Epoch 41/200\n",
      "50s - loss: 0.1344 - acc: 0.9987 - val_loss: 5.4857 - val_acc: 0.1271\n",
      "Epoch 42/200\n",
      "14s - loss: 0.1245 - acc: 0.9987 - val_loss: 5.5358 - val_acc: 0.1245\n",
      "Epoch 43/200\n",
      "50s - loss: 0.1139 - acc: 0.9991 - val_loss: 5.5937 - val_acc: 0.1258\n",
      "Epoch 44/200\n",
      "14s - loss: 0.1063 - acc: 0.9991 - val_loss: 5.5941 - val_acc: 0.1317\n",
      "Epoch 45/200\n",
      "53s - loss: 0.0974 - acc: 0.9992 - val_loss: 5.6668 - val_acc: 0.1219\n",
      "Epoch 46/200\n",
      "14s - loss: 0.0909 - acc: 0.9986 - val_loss: 5.7142 - val_acc: 0.1265\n",
      "Epoch 47/200\n",
      "53s - loss: 0.0841 - acc: 0.9991 - val_loss: 5.7441 - val_acc: 0.1213\n",
      "Epoch 48/200\n",
      "14s - loss: 0.0777 - acc: 0.9993 - val_loss: 5.8172 - val_acc: 0.1304\n",
      "Epoch 49/200\n",
      "51s - loss: 0.0710 - acc: 0.9992 - val_loss: 5.8438 - val_acc: 0.1213\n",
      "Epoch 50/200\n",
      "14s - loss: 0.0667 - acc: 0.9992 - val_loss: 5.8882 - val_acc: 0.1245\n",
      "Epoch 51/200\n",
      "51s - loss: 0.0623 - acc: 0.9991 - val_loss: 5.9214 - val_acc: 0.1232\n",
      "Epoch 52/200\n",
      "14s - loss: 0.0583 - acc: 0.9991 - val_loss: 5.9583 - val_acc: 0.1304\n",
      "Epoch 53/200\n",
      "52s - loss: 0.0540 - acc: 0.9991 - val_loss: 6.0173 - val_acc: 0.1206\n",
      "Epoch 54/200\n",
      "14s - loss: 0.0500 - acc: 0.9993 - val_loss: 6.0519 - val_acc: 0.1226\n",
      "Epoch 00053: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27bc0418358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          verbose=2, callbacks=callbacks_list,\n",
    "          epochs=200)\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = \"VGG19\"\n",
    "write_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.history['acc']\n",
    "\n",
    "\n",
    "#from pprint import pprint\n",
    "print(type(model.history))\n",
    "print(type(model))\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_model_history(model)\n",
    "# compute test accuracy\n",
    "#print(\"Accuracy on test data is: %0.2f\"%accuracy(X_valid, Y_valid, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Dvc-{}-{}.model'.format(LR, 'conv1')\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, im_size, im_size, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = dropout(convnet, 0.5)\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 120, activation='softmax')\n",
    "print(convnet.get_shape())\n",
    "\n",
    "# 2 is class categories count\n",
    "convnet = regression(convnet,\n",
    "                     optimizer='adam',learning_rate=LR,\n",
    "                     loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "\n",
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y},\n",
    "          n_epoch=50, validation_set=({'input': test_x},\n",
    "                                     {'targets': test_y}), \n",
    "          snapshot_step=1000, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "model.save(\"models/{}\".format(MODEL_NAME)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
