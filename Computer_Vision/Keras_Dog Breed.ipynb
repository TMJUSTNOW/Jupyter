{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Breeds\n",
    "\n",
    "https://www.kaggle.com/orangutan/keras-vgg19-starter\n",
    "\n",
    "https://www.kaggle.com/gaborfodor/use-pretrained-keras-models-lb-0-3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breed_class.csv',\n",
       " 'labels.csv',\n",
       " 'logs',\n",
       " 'pickle',\n",
       " 'sample_submission.csv',\n",
       " 'VGG19.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"D:\\My Computer\\DATA\\Dog_Breed_Identification\")\n",
    "\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "sample_submission= pd.read_csv(\"sample_submission.csv\")\n",
    "targets_series = pd.Series(labels['breed'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID has 32 characters\n",
    "# File names have 36 characters\n",
    "# suggesting the four last digits differentiate the dog within breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep():\n",
    "    print(\"Dog Breed Number:\", labels.shape)\n",
    "    print(\"Training Size:\", len(os.listdir(train_dir)))\n",
    "    print(\"Test Size:\", len(os.listdir(test_dir)))\n",
    "    print(\"Sample Sub Size:\", sample_submission.shape)\n",
    "\n",
    "    im_size = 90\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "\n",
    "    i = 0 \n",
    "    for f, breed in tqdm(labels.values):\n",
    "        img = cv2.imread('train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "        \n",
    "    for f in tqdm(sample_submission['id'].values):\n",
    "        img = cv2.imread('test/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "        \n",
    "    for (x) in [(x_train, \"x_train\"), (y_train,\"y_train\"), (x_test, 'x_test')]:\n",
    "        with open(\"pickle/{}.pickle\".format(x[1]), 'wb') as f:\n",
    "            pickle.dump(x[0], f)\n",
    "        \n",
    "#dataprep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 90, 90, 3)\n",
      "(10222, 120)\n",
      "(10357, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "dic= {}\n",
    "for name in [\"x_train\",\"y_train\",\"x_test\"]:\n",
    "    open_file = open(\"./Pickle/{}.pickle\".format(name), \"rb\")\n",
    "    dic[name] = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    \n",
    "y_train_raw = np.array(dic[\"y_train\"], np.uint8)\n",
    "x_train_raw = np.array(dic[\"x_train\"], np.float32) / 255.\n",
    "x_test  = np.array(dic[\"x_test\"], np.float32) / 255.\n",
    "\n",
    "del dic\n",
    "\n",
    "num_class = y_train_raw.shape[1]\n",
    "X_train, X_valid, Y_train, Y_valid = \\\n",
    "train_test_split(x_train_raw, y_train_raw, test_size=0.15, random_state=1)\n",
    "\n",
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "del x_train_raw, y_train_raw\n",
    "    \n",
    "## SEE ./ PICKLE FOLDER CREATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "# Write\n",
    "def write_model(model, modelname):\n",
    "    preds = model.predict(x_test, verbose=0)\n",
    "    sub = pd.DataFrame(preds)\n",
    "    # Set column names to those generated by the one-hot encoding earlier\n",
    "    col_names = one_hot.columns.values\n",
    "    sub.columns = col_names\n",
    "    # Insert the column id from the sample_submission at the start of the data frame\n",
    "    sub.insert(0, 'id', sample_submission['id'])\n",
    "    sub.to_csv(\"{}.csv\".format(modelname), index=False)\n",
    "       \n",
    "im_size = 90\n",
    "# Store Result, Parameters and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# Pretrained\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 20,270,264\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19 Pretrained Model\n",
    "# Not sure if I really need to iterate over this?\n",
    "    \n",
    "# Research Base Models\n",
    "base_model = VGG19(weights='imagenet',\n",
    "                   include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "# Add a new top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# This is the model we will train\n",
    "# This outputs the softmax, probabilistic consideration\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with Min_delta\n",
    "ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=40,\n",
    "          verbose=1, mode='auto')\n",
    "# Figure out how to assign name to it\n",
    "TB = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=2,  \n",
    "          write_graph=True, write_images=False)\n",
    "# Broken?\n",
    "MC = keras.callbacks.ModelCheckpoint('./save', monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True,\n",
    "                             mode='auto', period=5)\n",
    "\n",
    "\n",
    "callbacks_list = [ES,TB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tensorboard --logdir=models:\"D:\\My Computer\\DATA\\Dog_Breed_Identification\\logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 1534 samples\n",
      "Epoch 1/200\n",
      "15s - loss: 4.5413 - acc: 0.0540 - val_loss: 4.3019 - val_acc: 0.0815\n",
      "Epoch 2/200\n",
      "14s - loss: 3.5751 - acc: 0.1967 - val_loss: 4.1188 - val_acc: 0.1121\n",
      "Epoch 3/200\n",
      "14s - loss: 3.0978 - acc: 0.2868 - val_loss: 4.0655 - val_acc: 0.1258\n",
      "Epoch 4/200\n",
      "14s - loss: 2.7433 - acc: 0.3750 - val_loss: 4.0499 - val_acc: 0.1258\n",
      "Epoch 5/200\n",
      "14s - loss: 2.4620 - acc: 0.4442 - val_loss: 4.0183 - val_acc: 0.1310\n",
      "Epoch 6/200\n",
      "14s - loss: 2.2287 - acc: 0.4964 - val_loss: 4.0728 - val_acc: 0.1219\n",
      "Epoch 7/200\n",
      "14s - loss: 2.0366 - acc: 0.5517 - val_loss: 4.1162 - val_acc: 0.1252\n",
      "Epoch 8/200\n",
      "14s - loss: 1.8562 - acc: 0.6019 - val_loss: 4.0840 - val_acc: 0.1408\n",
      "Epoch 9/200\n",
      "14s - loss: 1.7054 - acc: 0.6469 - val_loss: 4.1350 - val_acc: 0.1375\n",
      "Epoch 10/200\n",
      "14s - loss: 1.5646 - acc: 0.6910 - val_loss: 4.1706 - val_acc: 0.1239\n",
      "Epoch 11/200\n",
      "14s - loss: 1.4542 - acc: 0.7167 - val_loss: 4.1663 - val_acc: 0.1460\n",
      "Epoch 12/200\n",
      "14s - loss: 1.3353 - acc: 0.7513 - val_loss: 4.2295 - val_acc: 0.1428\n",
      "Epoch 13/200\n",
      "14s - loss: 1.2326 - acc: 0.7799 - val_loss: 4.2672 - val_acc: 0.1278\n",
      "Epoch 14/200\n",
      "14s - loss: 1.1386 - acc: 0.8072 - val_loss: 4.2748 - val_acc: 0.1369\n",
      "Epoch 15/200\n",
      "14s - loss: 1.0539 - acc: 0.8261 - val_loss: 4.3142 - val_acc: 0.1349\n",
      "Epoch 16/200\n",
      "14s - loss: 0.9765 - acc: 0.8459 - val_loss: 4.3529 - val_acc: 0.1317\n",
      "Epoch 17/200\n",
      "14s - loss: 0.9028 - acc: 0.8664 - val_loss: 4.3898 - val_acc: 0.1304\n",
      "Epoch 18/200\n",
      "14s - loss: 0.8361 - acc: 0.8805 - val_loss: 4.4716 - val_acc: 0.1343\n",
      "Epoch 19/200\n",
      "14s - loss: 0.7756 - acc: 0.8983 - val_loss: 4.5282 - val_acc: 0.1232\n",
      "Epoch 20/200\n",
      "14s - loss: 0.7204 - acc: 0.9098 - val_loss: 4.5668 - val_acc: 0.1284\n",
      "Epoch 21/200\n",
      "14s - loss: 0.6656 - acc: 0.9235 - val_loss: 4.5566 - val_acc: 0.1271\n",
      "Epoch 22/200\n",
      "14s - loss: 0.6126 - acc: 0.9352 - val_loss: 4.6523 - val_acc: 0.1336\n",
      "Epoch 23/200\n",
      "14s - loss: 0.5701 - acc: 0.9433 - val_loss: 4.6627 - val_acc: 0.1278\n",
      "Epoch 24/200\n",
      "14s - loss: 0.5257 - acc: 0.9507 - val_loss: 4.7358 - val_acc: 0.1336\n",
      "Epoch 25/200\n",
      "15s - loss: 0.4858 - acc: 0.9572 - val_loss: 4.7465 - val_acc: 0.1330\n",
      "Epoch 26/200\n",
      "14s - loss: 0.4470 - acc: 0.9669 - val_loss: 4.8240 - val_acc: 0.1284\n",
      "Epoch 27/200\n",
      "14s - loss: 0.4143 - acc: 0.9702 - val_loss: 4.8563 - val_acc: 0.1369\n",
      "Epoch 28/200\n",
      "15s - loss: 0.3821 - acc: 0.9758 - val_loss: 4.9118 - val_acc: 0.1362\n",
      "Epoch 29/200\n",
      "15s - loss: 0.3535 - acc: 0.9784 - val_loss: 4.9365 - val_acc: 0.1330\n",
      "Epoch 30/200\n",
      "14s - loss: 0.3270 - acc: 0.9834 - val_loss: 4.9963 - val_acc: 0.1297\n",
      "Epoch 31/200\n",
      "14s - loss: 0.2990 - acc: 0.9872 - val_loss: 5.0364 - val_acc: 0.1304\n",
      "Epoch 32/200\n",
      "14s - loss: 0.2764 - acc: 0.9896 - val_loss: 5.1027 - val_acc: 0.1278\n",
      "Model took 473.87 seconds to train\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "callbacks_list=[\n",
    "                  keras.callbacks.TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H_%M_%S')),\n",
    "                        histogram_freq=0, write_graph=False, write_images=False),\n",
    "                  keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=.01, patience=7,\n",
    "                        verbose=0, mode='auto')]\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          verbose=2, callbacks=callbacks_list,\n",
    "          epochs=200)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"VGG19\"\n",
    "write_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
