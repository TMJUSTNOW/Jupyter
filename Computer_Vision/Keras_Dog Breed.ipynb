{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Breeds\n",
    "\n",
    "https://www.kaggle.com/orangutan/keras-vgg19-starter\n",
    "\n",
    "https://www.kaggle.com/gaborfodor/use-pretrained-keras-models-lb-0-3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breed_class.csv',\n",
       " 'labels.csv',\n",
       " 'logs',\n",
       " 'models',\n",
       " 'sample_submission.csv',\n",
       " 'save',\n",
       " 'test',\n",
       " 'train',\n",
       " 'VGG19.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"D:\\My Computer\\DATA\\Dog_Breed_Identification\")\n",
    "\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "sample_submission= pd.read_csv(\"sample_submission.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID has 32 characters\n",
    "# File names have 36 characters\n",
    "# suggesting the four last digits differentiate the dog within breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog Breed Number: (10222, 2)\n",
      "Training Size: 10222\n",
      "Test Size: 10357\n",
      "Sample Sub Size: (10357, 121)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dog Breed Number:\", labels.shape)\n",
    "print(\"Training Size:\", len(os.listdir(train_dir)))\n",
    "print(\"Test Size:\", len(os.listdir(test_dir)))\n",
    "print(\"Sample Sub Size:\", sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10222/10222 [00:21<00:00, 484.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10357/10357 [00:21<00:00, 477.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def dataprep():\n",
    "    targets_series = pd.Series(labels['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "\n",
    "    im_size = 90\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "\n",
    "    i = 0 \n",
    "    for f, breed in tqdm(labels.values):\n",
    "        img = cv2.imread('train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "        \n",
    "    for f in tqdm(sample_submission['id'].values):\n",
    "        img = cv2.imread('test/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "        \n",
    "    for (x) in [(x_train, \"x_train\"), (y_train,\"y_train\"), (x_test, 'x_test')]:\n",
    "        with open(\"pickle/{}.pickle\".format(x[1]), 'wb') as f:\n",
    "            pickle.dump(x[0], f)\n",
    "        \n",
    "#dataprep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 90, 90, 3)\n",
      "(10222, 120)\n",
      "(10357, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "dic= {}\n",
    "for name in [\"x_train\",\"y_train\",\"x_test\"]:\n",
    "    open_file = open(\"./Pickle/{}.pickle\".format(name), \"rb\")\n",
    "    dic[name] = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    \n",
    "y_train_raw = np.array(dic[\"y_train\"], np.uint8)\n",
    "x_train_raw = np.array(dic[\"x_train\"], np.float32) / 255.\n",
    "x_test  = np.array(dic[\"x_test\"], np.float32) / 255.\n",
    "\n",
    "del dic\n",
    "\n",
    "num_class = y_train_raw.shape[1]\n",
    "X_train, X_valid, Y_train, Y_valid = \\\n",
    "train_test_split(x_train_raw, y_train_raw, test_size=0.15, random_state=1)\n",
    "\n",
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "del x_train_raw, y_train_raw\n",
    "    \n",
    "## SEE ./ PICKLE FOLDER CREATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "# Write\n",
    "def write_model(model, modelname):\n",
    "    preds = model.predict(x_test, verbose=0)\n",
    "    sub = pd.DataFrame(preds)\n",
    "    # Set column names to those generated by the one-hot encoding earlier\n",
    "    col_names = one_hot.columns.values\n",
    "    sub.columns = col_names\n",
    "    # Insert the column id from the sample_submission at the start of the data frame\n",
    "    sub.insert(0, 'id', sample_submission['id'])\n",
    "    sub.to_csv(\"{}.csv\".format(modelname), index=False)\n",
    "       \n",
    "im_size = 90\n",
    "# Store Result, Parameters and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# Pretrained\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 20,270,264\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19 Pretrained Model\n",
    "# Not sure if I really need to iterate over this?\n",
    "    \n",
    "# Research Base Models\n",
    "base_model = VGG19(weights='imagenet',\n",
    "                   include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "# Add a new top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# This is the model we will train\n",
    "# This outputs the softmax, probabilistic consideration\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with Min_delta\n",
    "ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=40,\n",
    "          verbose=1, mode='auto')\n",
    "# Figure out how to assign name to it\n",
    "TB = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=2,  \n",
    "          write_graph=True, write_images=False)\n",
    "# Broken?\n",
    "MC = keras.callbacks.ModelCheckpoint('./save', monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True,\n",
    "                             mode='auto', period=5)\n",
    "\n",
    "\n",
    "callbacks_list = [ES,TB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=models:\"D:\\My Computer\\DATA\\Dog_Breed_Identification\\logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 1534 samples\n",
      "Epoch 1/200\n",
      "16s - loss: 4.5500 - acc: 0.0538 - val_loss: 4.2709 - val_acc: 0.0945\n",
      "Epoch 2/200\n",
      "14s - loss: 3.5894 - acc: 0.1900 - val_loss: 4.1467 - val_acc: 0.1050\n",
      "Epoch 3/200\n",
      "14s - loss: 3.1031 - acc: 0.2939 - val_loss: 4.0564 - val_acc: 0.1147\n",
      "Epoch 4/200\n",
      "15s - loss: 2.7434 - acc: 0.3713 - val_loss: 4.0126 - val_acc: 0.1382\n",
      "Epoch 5/200\n",
      "14s - loss: 2.4632 - acc: 0.4454 - val_loss: 4.0359 - val_acc: 0.1284\n",
      "Epoch 6/200\n",
      "14s - loss: 2.2347 - acc: 0.5012 - val_loss: 4.0233 - val_acc: 0.1349\n",
      "Epoch 7/200\n",
      "14s - loss: 2.0379 - acc: 0.5576 - val_loss: 4.0617 - val_acc: 0.1310\n",
      "Epoch 8/200\n",
      "14s - loss: 1.8617 - acc: 0.6003 - val_loss: 4.0627 - val_acc: 0.1434\n",
      "Epoch 9/200\n",
      "14s - loss: 1.7095 - acc: 0.6520 - val_loss: 4.1046 - val_acc: 0.1336\n",
      "Epoch 10/200\n",
      "14s - loss: 1.5680 - acc: 0.6898 - val_loss: 4.1330 - val_acc: 0.1369\n",
      "Epoch 11/200\n",
      "14s - loss: 1.4511 - acc: 0.7203 - val_loss: 4.1728 - val_acc: 0.1454\n",
      "Epoch 12/200\n",
      "14s - loss: 1.3314 - acc: 0.7499 - val_loss: 4.1817 - val_acc: 0.1389\n",
      "Epoch 13/200\n",
      "14s - loss: 1.2302 - acc: 0.7775 - val_loss: 4.2748 - val_acc: 0.1349\n",
      "Epoch 14/200\n",
      "15s - loss: 1.1428 - acc: 0.8013 - val_loss: 4.3180 - val_acc: 0.1317\n",
      "Epoch 15/200\n",
      "14s - loss: 1.0588 - acc: 0.8238 - val_loss: 4.3539 - val_acc: 0.1323\n",
      "Epoch 16/200\n",
      "14s - loss: 0.9749 - acc: 0.8494 - val_loss: 4.3958 - val_acc: 0.1291\n",
      "Epoch 17/200\n",
      "15s - loss: 0.9019 - acc: 0.8646 - val_loss: 4.3990 - val_acc: 0.1375\n",
      "Epoch 18/200\n",
      "14s - loss: 0.8361 - acc: 0.8856 - val_loss: 4.4927 - val_acc: 0.1310\n",
      "Epoch 19/200\n",
      "14s - loss: 0.7745 - acc: 0.8991 - val_loss: 4.4565 - val_acc: 0.1330\n",
      "Epoch 20/200\n",
      "14s - loss: 0.7163 - acc: 0.9108 - val_loss: 4.5401 - val_acc: 0.1310\n",
      "Epoch 21/200\n",
      "15s - loss: 0.6621 - acc: 0.9235 - val_loss: 4.5672 - val_acc: 0.1343\n",
      "Epoch 22/200\n",
      "14s - loss: 0.6137 - acc: 0.9365 - val_loss: 4.6543 - val_acc: 0.1310\n",
      "Epoch 23/200\n",
      "15s - loss: 0.5705 - acc: 0.9422 - val_loss: 4.6773 - val_acc: 0.1382\n",
      "Epoch 24/200\n",
      "15s - loss: 0.5233 - acc: 0.9518 - val_loss: 4.7414 - val_acc: 0.1258\n",
      "Epoch 25/200\n",
      "15s - loss: 0.4871 - acc: 0.9609 - val_loss: 4.7695 - val_acc: 0.1252\n",
      "Epoch 26/200\n",
      "14s - loss: 0.4486 - acc: 0.9650 - val_loss: 4.8172 - val_acc: 0.1265\n",
      "Epoch 27/200\n",
      "14s - loss: 0.4142 - acc: 0.9710 - val_loss: 4.8556 - val_acc: 0.1284\n",
      "Epoch 28/200\n",
      "15s - loss: 0.3832 - acc: 0.9751 - val_loss: 4.9162 - val_acc: 0.1297\n",
      "Epoch 29/200\n",
      "15s - loss: 0.3526 - acc: 0.9803 - val_loss: 4.9565 - val_acc: 0.1245\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-bcd18786a4bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Fitting the ANN to the Training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m classifier.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      9\u001b[0m        \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m        batch_size = 32, epochs = 200, verbose=2, callbacks=call_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "callbacks_list=[\n",
    "                  keras.callbacks.TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H_%M_%S')),\n",
    "                        histogram_freq=0, write_graph=False, write_images=False),\n",
    "                  keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=.005, patience=20,\n",
    "                        verbose=0, mode='auto')]\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          verbose=2, callbacks=callbacks_list,\n",
    "          epochs=200)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = \"VGG19\"\n",
    "write_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.history['acc']\n",
    "\n",
    "\n",
    "#from pprint import pprint\n",
    "print(type(model.history))\n",
    "print(type(model))\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_model_history(model)\n",
    "# compute test accuracy\n",
    "#print(\"Accuracy on test data is: %0.2f\"%accuracy(X_valid, Y_valid, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Dvc-{}-{}.model'.format(LR, 'conv1')\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, im_size, im_size, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "print(convnet.get_shape())\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.get_shape())\n",
    "convnet = dropout(convnet, 0.5)\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 120, activation='softmax')\n",
    "print(convnet.get_shape())\n",
    "\n",
    "# 2 is class categories count\n",
    "convnet = regression(convnet,\n",
    "                     optimizer='adam',learning_rate=LR,\n",
    "                     loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "\n",
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y},\n",
    "          n_epoch=50, validation_set=({'input': test_x},\n",
    "                                     {'targets': test_y}), \n",
    "          snapshot_step=1000, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "model.save(\"models/{}\".format(MODEL_NAME)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
