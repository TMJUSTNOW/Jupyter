{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Net\n",
    "\n",
    "Different from traditional neural nets, which connects every neuron between layers. Dimensionality issue with picture data would cause it to be too computationally expensive. Great for spatial data, where positioning matters.\n",
    "Sound, text, image, map.\n",
    "If rows and columns can be swapped, then position doesnt matters. \n",
    "\n",
    "Spatial Invariance: being able to determine an object regardless of the angle\n",
    "\n",
    "Processes:\n",
    "1. Receptive field: start of the pipeline, take a subset of the image for processing, then shift (Perhaps some overlap) and repeat. Stride size is the shift difference.\n",
    "2. Layering: hierarchical system of pattern recognition complexity.\n",
    "3.  \n",
    "\n",
    "Operations:\n",
    "Data: Matrix Form, 3d if processing color\n",
    "\n",
    "Feature Learning Block\n",
    "1. Convolution: Combining input with learned features. Multiply input through a series of matrices (aka: kernel, graph, map, filter). Outputs a dot product. Add together dot products to get degree of feature resemblance.\n",
    "2. Pooling: Triage of filters between layers. Technique is applied to each receptive field, and once again stride determines the shift distance between receptive fields.\n",
    "3. Normalization, Activation(Relu): Enables none-linear learning.\n",
    "    1. Relu= all negative numbers -> 0\n",
    "4. Regularization: Drop out- Randomly turns off nodes to train new routes, and prevent overfitting. (Taking psychedelics prevents human overfitting?)\n",
    "5. Optimization: Gradient descent- Backpropagation\n",
    "    1. Derivative of error to direct weights\n",
    "\n",
    "First layer starts large, and get more precise (small)\n",
    "\n",
    "- Classification:\n",
    "- Flatten\n",
    "- Fully Connected\n",
    "- Softmax\n",
    "\n",
    "Backpropagate to update weights\n",
    "\n",
    "Parameter Tuning:\n",
    "1. Neurons\n",
    "\n",
    "\n",
    "Other Applications:\n",
    "- Deconvolutional Neural Net- Flip the process and turn other input (eg. text) into an image\n",
    "- Generative Neural Net- Collide two Neural nets to mash and generate a new image (DEEP DREAM!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
